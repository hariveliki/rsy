---
title: "MC1RSY"
author: "Tobias Lauber"
date: "2023-10-05"
output: html_document
---
# 1. Load librarys
```{r setup, include=FALSE}
library(tidyverse)
library(recommenderlab)
library(lsa) # might need for cosine function
library(dplyr)
library(tidyr) # for plot
```

für Kapitel in Outline schauen. Kapitel starten mit Hash. Unterkapitel mit hashhash. unter unter hashhashhash

# 2. load data
```{r cars}
data("MovieLense")
str(MovieLense)
```
## 2.1 Own testing
```{r}
summary(MovieLense)
```
type:
```{r}
class(MovieLense)
```
see it as data frame
```{r}
# Convert the realRatingMatrix to a data frame
movie_data <- as(MovieLense, "data.frame")


# View the first few rows of the data frame
head(movie_data, 20)
```
```{r}
column_names <- colnames(MovieLense)
#print(column_names)
```


# 6.1 Explorative Datenanalyse [10 Punkte]
1)
```{r}
#we look at slotnames
slotNames(MovieLense)
```

```{r}
#classes
class(MovieLense@data)
```
We now look at all the unique vector ratings
```{r}
vector_ratings <- as.vector(MovieLense@data)
unique(vector_ratings)
```
A rating of 0 indicates a missing rating, so we have to remove it
```{r}
vector_ratings <- vector_ratings[vector_ratings != 0]
```

we now look, how often a movie was watched, with the help of a dataframe

```{r}
views_per_movie <- colCounts(MovieLense)

dfrat <- data.frame(
  movie = names(views_per_movie),
  views = views_per_movie
  )
dfviews <- dfrat[order(dfrat$views, decreasing = TRUE), ]
head(dfviews)
```
here we have our 10 most watched movies as a plot

```{r}
ggplot(dfviews[1:10, ], aes(x = movie, y = views)) +
  geom_bar(stat="identity") + 
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  ggtitle("Number of views of the top movies")
```

##genres

genres are in movielensemeta data.
1 means the genre is represent in the movie.
0 means it is not.
By using that logic, we can summarise the columns, and the result is the number of occurenses of the genres in movielense.
```{r}
#Create new df and remove useless columns
popular_genresdf <- MovieLenseMeta %>% select(-c('title', 'year', 'url'))

# count the number of columns
views_per_genre <- popular_genresdf %>%
  summarise(across(everything(), sum)) %>%
  arrange(desc(.))

views_per_genre
```
```{r}
# Convert data to the pivot long format
views_per_genre_long <- views_per_genre %>%
  pivot_longer(everything(), names_to = "Column", values_to = "Sum")

# Create a bar plot
ggplot(views_per_genre_long, aes(x = Column, y = Sum, fill = Column)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = Sum), vjust = -0.5) +  # Add labels above the bars
  labs(title = "Sum of Each Genre", x = "Genre", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+# Rotate xaxis
  coord_cartesian(ylim = c(0, max(views_per_genre_long$Sum) + 200)) +
  guides(fill = 'none')


```

## 6.1  2)

```{r}
MovieLenseMeta
```

```{r}
colnames(movie_data)
```


```{r}
movie_data
```

We need to join the 2 dataframes. The only thing they have in common are the movie titles. So that is 
```{r}
# Merge the data frames based on movie titles. We will further use this

merged_data <- left_join(movie_data, MovieLenseMeta, 
                         by = c("item" = "title"))

# Create a new data frame with genres and ratings
genre_ratings <- merged_data %>%
  select(Action:Western, rating) %>%
  gather(genre, is_genre, Action:Western) %>%
  filter(is_genre == 1) %>%
  group_by(genre) %>%
  summarize(
    avg_rating = mean(rating),
    median_rating = median(rating)
  )

ggplot(genre_ratings, aes(x = genre, y = avg_rating, fill = avg_rating)) +
  geom_bar(stat = "identity") +
  geom_text(aes(label = round(avg_rating, 2), vjust = -0.5), size = 3) +
  coord_cartesian(ylim = c(0,5)) +
  xlab("Genre") +
  ylab("Average Rating") +
  ggtitle("Distribution of Ratings by Genre")+
  scale_fill_gradient(low = "black", high = "blue") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

## 6.1 3)

```{r}
merged_data
```
Mittlere Rating Filme
```{r}
# Gruppiere nach Filme und berechne den Durchschnitt

average_ratings_per_movie <- merged_data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating))

median_rating <- median(average_ratings_per_movie$mean_rating)
min_rating <- min(average_ratings_per_movie$mean_rating)
max_rating <- max(average_ratings_per_movie$mean_rating)
mean_rating <- mean(average_ratings_per_movie$mean_rating)

# Resultate
cat("Median Filmbewertung:", median_rating, "\n")
cat("Minimale Filmbewertung:", min_rating, "\n")
cat("Maximale Filmbewertung:", max_rating, "\n")
cat("Durchschnittliche Filmbewertung:", mean_rating, "\n")
```
Plot Mittlere Rating Filme
```{r}
average_ratings_per_movie <- merged_data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating))

# Plot
ggplot(data = average_ratings_per_movie, aes(x = mean_rating)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  labs(title = "Durchschnittliche Ratings Filme",
       x = "Durchschnittliche Bewertung",
       y = "Nummer an Filmen")
```


Mittlere Ratings User
```{r}
average_ratings_per_user <- merged_data %>%
  group_by(user) %>%
  summarize(mean_rating = mean(rating))

median_rating <- median(average_ratings_per_user$mean_rating)
min_rating <- min(average_ratings_per_user$mean_rating)
max_rating <- max(average_ratings_per_user$mean_rating)
mean_rating <- mean(average_ratings_per_user$mean_rating)

# Resultate
cat("Median durchschnittliche Userbewertung:", median_rating, "\n")
cat("Minimale durchschnittliche Userbewertung:", min_rating, "\n")
cat("Maximale durchschnittliche Userbewertung:", max_rating, "\n")
cat("Durchschnittliche durchschnittliche Userbewertung:", mean_rating, "\n")
```
Plot Mittlere Ratings User
```{r}
ggplot(data = average_ratings_per_user, aes(x = mean_rating)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  labs(title = "Durchschnittliche Ratings User",
       x = "Durchschnittliche Bewertung",
       y = "Nummer an Usern")
```


## 6.1 4)

```{r}
normalized_ratings <- merged_data %>%
  group_by(user) %>%
  mutate(normalized_rating = (rating - mean(rating)) / sd(rating))

median_normalized_rating <- median(normalized_ratings$normalized_rating)
min_normalized_rating <- min(normalized_ratings$normalized_rating)
max_normalized_rating <- max(normalized_ratings$normalized_rating)
mean_normalized_rating <- mean(normalized_ratings$normalized_rating)

# Resultate
cat("Median der normalisierten avg Userbewertungen:", median_normalized_rating, "\n")
cat("Minimale normalisierte avg Userbewertung:", min_normalized_rating, "\n")
cat("Maximale normalisierte avg Userbewertung:", max_normalized_rating, "\n")
cat("Durchschnittliche normalisierte avg Userbewertung:", mean_normalized_rating, "\n")
```
Plot die Durchschnittliche Userratings. Diesmal mit ner Z score Normalisierung
```{r}
ggplot(data = normalized_ratings, aes(x = normalized_rating)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  labs(title = "Durchschnittliche Ratings User",
       x = "Durchschnittliche Bewertung",
       y = "Nummer an Usern")
```
Wir können sehen, das mithilfe von Normalisierung sich der Graph nach links verschiebt -> Der urchschnitt der User Ratings ist schlechter.


## 6.1 5)
```{r}
colnames(merged_data)
```
#Einschub ir nehmen jetzt normalized ratings
```{r}
matrix_stand <- normalize(MovieLense, method="Z-Score")
movie_data <- as(matrix_stand, "data.frame") #movie lense durch matrix stand
merged_data <- left_join(movie_data, MovieLenseMeta, 
                         by = c("item" = "title"))

```


# 6.2 Datenreduktion [6 Punkte]
600 nutzer und 700 Filme

```{r}
# Filtere 400 aktivste users
top_400_users <- merged_data %>%
  group_by(user) %>%
  summarize(total_ratings = n()) %>%
  arrange(desc(total_ratings)) %>%
  slice(1:400) %>%
  select(user)


# Filter the top 700 movies
top_movies <- merged_data %>%
  group_by(item) %>%
  summarize(total_ratings = n()) %>%
  arrange(desc(total_ratings)) %>%
  slice(1:700) %>%
  select(item)

# Reduziere dataset für Filme und User
top_400_data <- merged_data %>%
  filter(user %in% top_400_users$user, item %in% top_movies$item)

```
For 400

Before
```{r}
num_users_before <- length(unique(merged_data$user))
num_movies_before <- length(unique(merged_data$item))
sparsity_before <- 1 - (nrow(merged_data) / (num_users_before * num_movies_before))

# Output before reduction
cat("Number of users before reduction:", num_users_before, "\n")
cat("Number of movies before reduction:", num_movies_before, "\n")
cat("Sparsity before reduction:", sparsity_before, "\n")
```

After
```{r}
num_users_after <- length(unique(top_400_data$user))
num_movies_after <- length(unique(top_400_data$item))
sparsity_after <- 1 - (nrow(top_400_data) / (num_users_after * num_movies_after))

# Output after reduction
cat("Number of users after reduction:", num_users_after, "\n")
cat("Number of movies after reduction:", num_movies_after, "\n")
cat("Sparsity after reduction:", sparsity_after, "\n")
```
Das macht Sinn, denn wenn wir die User welche weniger Filme schauen rauskicken, dann sollte sich die Sparsity veringern.

plot Avarage ratings. Wir benutzen gridExtra für einfaches plotten

```{r}
library(gridExtra)

avg_ratings_400 <- top_400_data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating))

avg_ratings_full <- merged_data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating))

avg400 <- ggplot(data = avg_ratings_400, aes(x = mean_rating)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  labs(title = "400er Reduktion",
       x = "Durchschnittliche Bewertung",
       y = "Anzahl Filme")

avgfull <- ggplot(data = avg_ratings_full, aes(x = mean_rating)) +
  geom_histogram(binwidth = 0.1, fill = 'blue', color = 'black') +
  labs(title = 'voller Datensatz',
       x = "Durchschnittliche Bewertung",
       y = "Anzahl Filme")

grid.arrange(avg400, avgfull, ncol = 2) 

```


600

```{r}
top_600_users <- merged_data %>%
  group_by(user) %>%
  summarize(total_ratings = n()) %>%
  arrange(desc(total_ratings)) %>%
  slice(201:600) %>%
  select(user)

# Filter the top 700 movies
top_movies <- merged_data %>%
  group_by(item) %>%
  summarize(total_ratings = n()) %>%
  arrange(desc(total_ratings)) %>%
  slice(1:700) %>%
  select(item)

# Reduziere dataset für Filme und User
top_600_data <- merged_data %>%
  filter(user %in% top_600_users$user, item %in% top_movies$item)
```


Nochmal, das war bevor der Datenreduktion
```{r}
num_users_before <- length(unique(merged_data$user))
num_movies_before <- length(unique(merged_data$item))
sparsity_before <- 1 - (nrow(merged_data) / (num_users_before * num_movies_before))

# Output before reduction
cat("Number of users before reduction:", num_users_before, "\n")
cat("Number of movies before reduction:", num_movies_before, "\n")
cat("Sparsity before reduction:", sparsity_before, "\n")
```
Das ist nachdem man auf die 600 relevantesten User reduziert hat, ohne die 200 relevantesten User.

Plot average ratings für 600
```{r}
avg_ratings_600 <- top_600_data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating))

avg_ratings_full <- merged_data %>%
  group_by(item) %>%
  summarize(mean_rating = mean(rating))

avg600 <- ggplot(data = avg_ratings_600, aes(x = mean_rating)) +
  geom_histogram(binwidth = 0.1, fill = "blue", color = "black") +
  labs(title = "600er Reduktion",
       x = "Durchschnittliche Bewertung",
       y = "Anzahl Filme")

avgfull <- ggplot(data = avg_ratings_full, aes(x = mean_rating)) +
  geom_histogram(binwidth = 0.1, fill = 'blue', color = 'black') +
  labs(title = 'voller Datensatz',
       x = "Durchschnittliche Bewertung",
       y = "Anzahl Filme")

grid.arrange(avg600, avgfull, ncol = 2) 
```



```{r}
num_users_after <- length(unique(top_600_data$user))
num_movies_after <- length(unique(top_600_data$item))
sparsity_after <- 1 - (nrow(top_600_data) / (num_users_after * num_movies_after))

# Output after reduction
cat("Number of users after reduction:", num_users_after, "\n")
cat("Number of movies after reduction:", num_movies_after, "\n")
cat("Sparsity after reduction:", sparsity_after, "\n")
```

Die Sparsity ist zwar besser als zuvor, aber natürlich schlechter als bei den top 400 Usern, da man statt den 200 meist aktivsten Usern die 401-600 aktivsten Nutzer hat. 


## 6.2 3)

```{r}
head(top_400_data)
```
Die Formel ist: 

IOU = (# gemeinsame Filme) / (#Filme in beiden df zusammen )

```{r}
# Distinkte Movies / User für die Beiden Dataframes
anzahl_movies_400 <- n_distinct(top_400_data$item)
anzahl_users_400 <- n_distinct(top_400_data$user)

anzahl_movies_600 <- n_distinct(top_600_data$item)
anzahl_users_600 <- n_distinct(top_600_data$user)

# Intersection
common_movies <- intersect(top_400_data$item, top_600_data$item)
common_users <- intersect(top_400_data$user, top_600_data$user)

#IOU
IOU_movies <- length(common_movies) / (anzahl_movies_400 + anzahl_movies_600 - length(common_movies))

IOU_users <- length(common_users) / (anzahl_users_400 + 
              anzahl_users_600 - length(common_users))

cat("Intersection over Union für Filme:", IOU_movies, "\n")
cat("Intersection over Union für Nutzer:", IOU_users, "\n")
```
Dieses Resultat war nach unserer Datentrennung logisch, da wir die gleichen Filme verwenden und 0.333 macht auch Sinn, da nur die User 201-400 in beiden dataframes vorkommen.




# 6.3 Analyse Ähnlichkeitsmatrix [12 Punkte]

```{r}
#create real rating matrix
rrm_400 <- top_400_data[, c("user", "item", "rating")]
rrm_400 <- as(rrm_400, 'realRatingMatrix')
#str(rrm_400)
```

```{r}
#real rating matrix 600
rrm_600 <- top_600_data[, c("user", "item", "rating")]
rrm_600 <- as(rrm_600, 'realRatingMatrix')
```


## Datensatz 400
Create traintestsplit
```{r}
set.seed(7)
my_sample <- sample(c(TRUE,FALSE), nrow(rrm_400), replace = TRUE,
                    prob = c(0.8, 0.2))

train_400 <- rrm_400[my_sample, ]
test_400 <- rrm_400[!my_sample, ]
```

Item Based Collaberative Filtering for 400 rrm
```{r}
IBCF_model <- Recommender(train_400, method = 'IBCF',
                          param = list(method = 'Cosine', k = 30))
```

Now we plot a heatmap of the top_400 similarity matrix
```{r}
sim_400 <- getModel(IBCF_model)$sim
image(getModel(IBCF_model)$sim, 
      main = 'top_400 similarity matrix Heatmap')
```

## 6.3 3)
generelle Verteilung der Anzahl an 'Auftauchen' in der Cosine Ähnlichkeitsmatrix
```{r}
sums400 <- colSums(sim_400 != 0) 
twentytop_400 <- head(sort(sums400, decreasing = TRUE), 20)
hist(sums400, breaks = 50, main = 'Distribution in Similarity Matrix sim_400', xlab = '#Auftauchungen', ylab = '#Movies')
```
Wir sehen, dass ein grosser ANteil an Movies gar nicht bis nur sehr wenig vorkommt. Der grösste ANteil an Filmen liegt zwischen 0 und 50 Auftauchungen. Die anzahl Filme pro Auftauchungen nehmen je grösser die #Auftauchungen werden immer mehr ab



```{r}
twentytop_400
```
Dies hier sind die 20 Filme, welche die meiste #Auftauchungen hatten.

Analyse mit top_400_data
```{r}
ggplot() + geom_histogram(data = top_400_data %>% group_by(item) %>%
                            count(), aes(n), binwidth = 0.05, color = 'blue', fill = 'white', alpha = 0.5) +
  labs(title = 'top_400_data: Number of Ratings per Movie',
       x = '#ratings', y = '#movies', subtitle = 'top 20 Movies from cos IBCF from above in green') +
  geom_vline(xintercept = twentytop_400, color = 'green')
```

Unsere Filme des IBCF sind eher im Mittelfeld der ratings. Wir fragen uns, ob wir dies vielleicht nicht noch optimieren können.


HYPOTHESE: Durch das entfernen von NA werten aus unserer Similarity Matrix, werden Filme mit mehr Ratings gewählt. Wir werden diese Hypothese
nachdem wir die Ratings dieser gewählten Filme anschauen überprüfen.


Ratings der 20 Filme
```{r}
names_twentytop_400 <- names(twentytop_400)

top20simmrat = top_400_data %>% group_by(item) %>% 
  filter(item %in% names_twentytop_400)

ggplot() + geom_histogram(data = top20simmrat, aes(rating), binwidth = 0.1) + facet_wrap(vars(top20simmrat$item)) +
  labs(x = ' normalized_ratings', 
       y = '#ratings', title = 'Movie ratings distribution')
```

## Datensatz 600


```{r}
#real rating matrix 600
rrm_600 <- top_600_data[, c("user", "item", "rating")]
rrm_600 <- as(rrm_600, 'realRatingMatrix')
```

traintest split
```{r}
set.seed(7)
my_sample <- sample(c(TRUE,FALSE), nrow(rrm_600), replace = TRUE,
                    prob = c(0.8, 0.2))

train_600 <- rrm_600[my_sample, ]
test_600 <- rrm_600[!my_sample, ]
```


Item Based Collaberative Filtering for 600 rrm
```{r}
IBCF_model <- Recommender(train_600, method = 'IBCF',
                          param = list(method = 'Cosine', k = 30))
```

Now we plot a heatmap of the top_600 similarity matrix
```{r}
sim_600 <- getModel(IBCF_model)$sim
image(getModel(IBCF_model)$sim, 
      main = 'top_600 similarity matrix Heatmap')
```

generelle Verteilung der Anzahl an 'Auftauchen' in der Cosine Ähnlichkeitsmatrix
```{r}
sums600 <- colSums(sim_600 != 0) 
twentytop_600 <- head(sort(sums600, decreasing = TRUE), 20)
hist(sums600, breaks = 50, main = 'Distribution in Similarity Matrix sim_600', xlab = '#Auftauchungen', ylab = '#Movies')
```
Wir sehen, dass die meisten Auftauchungen hier klar um 0 sind.

Hier sind unsere 20 hüfigsten Filme
```{r}
twentytop_600
```
Interessant ist das Filme 'Fallen (1998)' welcher am meisten im
Datensatz 400 auftrat, hier nicht einmal die top20 schafft.


Analyse mit top_600_data
```{r}
ggplot() + geom_histogram(data = top_600_data %>% group_by(item) %>%
                            count(), aes(n), binwidth = 0.05, color = 'blue', fill = 'white', alpha = 0.5) +
  labs(title = 'top_600_data: Number of Ratings per Movie',
       x = '#ratings', y = '#movies', subtitle = 'top 20 Movies from cos IBCF from above in green') +
  geom_vline(xintercept = twentytop_600, color = 'green')
```
Wir nehmen erneut Filme mit einigen Ratings, aber nicht die Filme mit den
meisten Ratings. Wir schauen noch, ob sich das ganze optimieren lässt.

## Na durch 0 ersetzten. In Arbeit
```{r}

```


# 6.4
Als erstes wählen wir 100 zufällige Filme. 
```{r}
set.seed(7)
index <- sort(sample(1:nrow(MovieLense), 100)) #wähle 100 zufällige Filme
oursample <- MovieLense[index]
#reguläre Werte Matrix
oursample_Matrix <- as(oursample, "matrix")
oursample_Matrix[is.na(oursample_Matrix)] <- 0 #ersetze na durch 0

#binäre Werte Matrix
oursample_bin <- binarize(oursample,4)
oursample_Matrix_bin <- as(oursample_bin, "matrix")
```

Nun erstellen wir eine Jaccard SImilarity Funktion

```{r}
jaccard_similarity <- function(M) {
  A <- tcrossprod(M)
  im <- which(A > 0, arr.ind=TRUE)
  b <- rowSums(M)
  Aim <- A[im]
  sparseMatrix(
    i = im[,1],
    j = im[,2],
    x = Aim / (b[im[,1]] + b[im[,2]] - Aim),
    dims = dim(A)
  )
}
```


Wir nutzen die Jaccard similarity Funktion auf unsere binären Daten
```{r}
jaccard_sim = as(jaccard_similarity(oursample_Matrix_bin), "matrix")
```

Wir erstellen eine Cosinus Similarity Funktion
```{r}
cosinus_similarity <- function(M) 
{
  similarity <- M / sqrt(rowSums(M * M))
  similarity[is.na(similarity)] = 0
  similarity <- similarity %*% t(similarity)
  similarity <- as(similarity, "matrix")
 
}   
```


Wir nutzen die Cosinus Similarity auf unsere regulären Daten
```{r}
cosinus_sim <- cosinus_similarity(oursample_Matrix)
```


## 6.4.2 Funktionsvergleich
Wir vergleichen unsere Cosinus-Similarity Funktion mit denen aus recommenderlab auf unseren sample Datensatz.
```{r}
realRM <- as(oursample_Matrix, "realRatingMatrix")
cosine_rec = as.matrix(similarity(realRM, method="cosine", which="users"))
diag(cosine_rec) <- 1
rescale <- function(x) { return(1/2*(x+1))}
co_sim_rec = apply(cosinus_sim, 1, rescale)

max(abs(cosine_rec - co_sim_rec),na.rm = TRUE)
```

REcommenderlab scalt die Matrix um. Also machen wir das auch damit wir überhaubt vergleichen können

Wir überprüfen nun, ob unser cosinus recommender mit dem von recommenderlabs übereinstimmt.
```{r}
all.equal(cosine_rec, co_sim_rec)
```
Ja, macht er.

Wir vergleichen nun noch unsere Implementierung mit der von dem package proxy


```{r}
library(proxy)

# Cosine Similarity mit proxy
proxy_cosine <- as(cosine(t(oursample_Matrix)), "matrix")

# Vergleich
max(abs(cosinus_sim - proxy_cosine))
all.equal(cosinus_sim, proxy_cosine)
```
Wir sehen, auch dieser Vergleich mit proxy fällt positiv aus.

## Vergleich unserer Funktionen

```{r}
max(abs(cosinus_sim - jaccard_sim), na.rm = TRUE)
all.equal(cosinus_sim, jaccard_sim)
```
Mit einer mean relative difference von 0.6151852 sind sie nicht sehr ähnlich. Dies liegt daran,

Visuallisieren der Funktionen:

```{r}
library(ggplot2)
library(reshape2)

# Daten für die Heatmap vorbereiten
cosinus_melted <- melt(cosinus_sim)
jaccard_melted <- melt(jaccard_sim)

# Plotte cos Heatmap
movie_labels <- rownames(cosinus_sim)

# long format
cos_sim_df <- as.data.frame(as.table(cosinus_sim))
cos_sim_df$Var1 <- factor(cos_sim_df$Var1, levels = movie_labels)
cos_sim_df$Var2 <- factor(cos_sim_df$Var2, levels = movie_labels)

# heatmap
ggplot(cos_sim_df, aes(Var1, Var2, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(title = "Cosine Similarity Matrix", x = "Movies", y = "Movies")+
  scale_x_discrete(labels = rep("", nrow(cos_sim_df))) +
  scale_y_discrete(labels = rep("", nrow(cos_sim_df)))

#jaccard heatmap
ggplot() +
  geom_tile(data = jaccard_melted, aes(x = Var1, y = Var2, fill = value)) +
  labs(title = "Jaccard Similarity Matrix") +
  theme_minimal()
```

```{r}

```


```{r}
# Beispiel-Daten mit größeren Dimensionen
set.seed(7)
cosinus_sim_large <- matrix(runif(750^2), nrow = 750)

# Melt-Funktion
cosinus_melted_large <- melt(cosinus_sim_large)

# Erstelle Heatmap mit angepassten Einstellungen
ggplot(cosinus_melted_large, aes(Var1, Var2, fill = value)) +
  geom_tile() +
  scale_x_continuous(breaks = seq(1, 750, by = 50)) +
  scale_y_continuous(breaks = seq(1, 750, by = 50)) +
  labs(title = "Cosine Similarity Heatmap") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1), 
        legend.position = "right")
```


```{r}
movie_labels <- rownames(cosinus_sim)

# Create a long-format data frame for ggplot
cos_sim_df <- as.data.frame(as.table(cosinus_sim))
cos_sim_df$Var1 <- factor(cos_sim_df$Var1, levels = movie_labels)
cos_sim_df$Var2 <- factor(cos_sim_df$Var2, levels = movie_labels)

# Plot the heatmap
ggplot(cos_sim_df, aes(Var1, Var2, fill = Freq)) +
  geom_tile() +
  scale_fill_gradient(low = "white", high = "blue") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)) +
  labs(title = "Cosine Similarity Matrix", x = "Movies", y = "Movies")+
  scale_x_discrete(labels = rep("", nrow(cos_sim_df))) +
  scale_y_discrete(labels = rep("", nrow(cos_sim_df)))
```

# 6.5

## Datensatz 400

Wir erstellen sowohl cosinus IBCF als auch cosinus UBCF
```{r}
# IBCF 15 Empfehlungen
recmod_ibcf_400 <- Recommender(train_400, method = 'IBCF', param = list(method = 'Cosine', k = 30))

rec_ibcf_400 <- as(predict(recmod_ibcf_400, test_400, n =15), 'list')

# UBCF 15 Empfehlungen
recmod_ubcf_400 <- Recommender(train_400, method = 'UBCF', param = list(method = 'Cosine', nn = 30))

rec_ubcf_400 <- as(predict(recmod_ubcf_400, test_400, n = 15), 'list') #note:  should it not be test 400? was prev train_400


```


```{r}
recommended_400 <- data.frame(matrix(ncol = 17, nrow = 0))

for (i in rec_ibcf_400) {
  combined <- i
  combined['rectype'] <- 'ibcf'
  recommended_400 <-  rbind(recommended_400, combined)    #recommended mit ibcf und später ubcf
  
}

# jetzt noch ubcf dazu
for (i in rec_ubcf_400) {
  combined <- i
  combined['rectype'] <- 'ubcf'
  recommended_400 <-  rbind(recommended_400, combined)  
}

colnames(recommended_400) <- c(0:14, 'rectype')

#resultate wieder ins pivot-long format bringen
recommended_400_long <- recommended_400 %>% pivot_longer(cols = 0:15) %>%
  arrange(rectype, value)
```

Wir müssen nun die Movie Titel unique machen
```{r}
recommended_400_long$movie <- with(recommended_400_long, match(value, unique(value)))
```

wir teilen Item Based collaborative Filtering modell und 
User Bsed Collaborative Filtering
```{r}
ibcf_400 <- recommended_400_long %>% filter(rectype == 'ibcf')
ubcf_400 <- recommended_400_long %>% filter(rectype == 'ubcf')
```

Anzahl an unique Filmen bei unserem IBCF
```{r}
print('Das ist die Anzahl an unique Filmen in IBCF')
print(length(unique(ibcf_400$value)))
```
## note to self: 
Wie geht dies genau? Wir haben 700 filme im Datensatz. Das heisst, ein grosser Teil der Fime wird empfohlen

```{r}
ibcf_400
```


Anzahl an unique Filmen bei unserem UBCF
```{r}
print('Das ist die Anzahl an unique Filmen in UBCF')
print(length(unique(ubcf_400$value)))
```
## kann hier noch etwas weiter analysieren. Z.B intersection

## plots

für 400 Data

wir machen einen stacked plot
```{r}
ggplot(recommended_400_long, aes(x = movie)) + 
  geom_histogram(bins = 400, aes(fill = rectype))
```
Wir können sehen, dass die meisten recommendations bei den meist recommendeted filmen von UBCF kommen. IBCF ist viel breiter verteilt.


wir plotten die beiden Recommender getrennt
```{r}
ggplot(recommended_400_long) + 
  aes(x =movie, fill = rectype) +
  geom_histogram(bins = 600) + 
  facet_grid(rectype ~ .) +
  labs(x = 'Film ID', y = '#recommendations',
       title = 'Recommendations: top_400_data') 
```
Wir können sehen, das es bei ubcf mehr filme gibt, welche sehr oft empfohlen wurden. Item based collaborative filtering hat wie wir zuvor gesehen haben, mehr einzigartige Filme, jedoch werden die Filme nie über 25 mal empfohlen, was man bei UBCF deutlich häufiger sieht.
Dies liegt wohl daran, dass sich die USER ähnlicher sind als die ITEMS.


## 6.5.2      3 Nutzer

wir schauen, wie die Nutzerund Filme verteilt sind.
```{r}
movie_unique <- length(unique(recommended_400_long$movie))

print('ANzahl an verschiedenen Filmen:')
print(movie_unique)


```



 3 Testnutzer
```{r}
ibcf_400
```
Zuvor, haben wir die Nutzer vernachlässigt. Wir können sowohl bei IBCF als auch bei UBCF  nicht sehen, von welchem User sie kommen. Das müssen wir ändern.

```{r}
recommended_400_long
```

wir nehmen einfach die ersten 3 als Vergleich, bei unserem alten recommender.
```{r}
rec_ibcf_400$'0'
rec_ubcf_400$'0'
```

```{r}
class(rec_ubcf_400$'0')
```

```{r}
# Wähle die Top-15 Empfehlungen für die ersten drei Nutzer von IBCF
ibcf_top15_user1 <- rec_ibcf_400$'0'[1:15]
ibcf_top15_user2 <- rec_ibcf_400$'1'[1:15]
ibcf_top15_user3 <- rec_ibcf_400$'2'[1:15]

# Wähle die Top-15 Empfehlungen für die ersten drei Nutzer von UBCF
ubcf_top15_user1 <- rec_ubcf_400$'0'[1:15]
ubcf_top15_user2 <- rec_ubcf_400$'1'[1:15]
ubcf_top15_user3 <- rec_ubcf_400$'2'[1:15]

# Erstelle eine Vergleichstabelle
comparison_table <- data.frame(
   # Annahme: Die Zeilen repräsentieren die Top-15 Empfehlungen
  IBCF_User1 = ibcf_top15_user1,
  UBCF_User1 = ubcf_top15_user1,
  IBCF_User2 = ibcf_top15_user2,
  UBCF_User2 = ubcf_top15_user2,
  IBCF_User3 = ibcf_top15_user3,
  UBCF_User3 = ubcf_top15_user3
)

# Gib die Vergleichstabelle aus
print(comparison_table)
```

Hier sind die gemeinsamen Filme
```{r}
print('für user 1: ')
print(intersect(ibcf_top15_user1,ubcf_top15_user1))
cat('\n')

print('für user 2: ')
print(intersect(ibcf_top15_user2,ubcf_top15_user2))
cat('\n')

print('für user 3: ')
print(intersect(ibcf_top15_user3,ubcf_top15_user3))
```
Wir sehen, die Recommendations von IBCF und UBCF für unsere 3 User sind fast vollständig unterschiedlich. User 1 hat 1, user 2 hat 2 und user 3 hat keine gemeinsamen Filme.


# 6.6

Als Erinnerung, hier sind unsere Recommender aus Aufgabe 5
```{r}
# IBCF 15 Empfehlungen
recmod_ibcf_400 <- Recommender(train_400, method = 'IBCF', param = list(method = 'Cosine', k = 30))

rec_ibcf_400 <- as(predict(recmod_ibcf_400, test_400, n =15), 'list')

# UBCF 15 Empfehlungen
recmod_ubcf_400 <- Recommender(train_400, method = 'UBCF', param = list(method = 'Cosine', nn = 30))

rec_ubcf_400 <- as(predict(recmod_ubcf_400, test_400, n = 15), 'list')
```

Nun können wir die Intersektion bon IBCF und UBCF für data_400 plotten.

Ordinales Rating
```{r}
list_ord <- unlist(names(rec_ubcf_400) %>% map(~ (sum(rec_ibcf_400[[.x]] %in%
                                                      rec_ubcf_400[[.x]]))/ 
                     15 * 100))

df_ord <- as.data.frame(list_ord)
#df_ord
```


```{r}
ggplot() + geom_histogram(data = df_ord, aes(list_ord), binwidth = 1) +
  labs(title = 'Ordinal rating: Intersection IBCF/UBCF',
       x = 'Intersection in %',
       y = '#Users')
```

## noch nicht ganz fertig, weiss nicht ganz wie weiter
```{r}

```



# 6.7
Hier vergleichen wir IBCF vs SVD

Wir benutzen dabei die selbe vorgehensweise, wie bei aufgabe 6

```{r}
n = 15

#ibcf
recmod_ibcf_400 <- Recommender(train_400, method = 'IBCF', param = list(method = 'Cosine', k = 30))

rec_ibcf_400 <- as(predict(recmod_ibcf_400, test_400, n = n), 'list')



#svd 10

recmod_svd_400_10 <- Recommender(train_400, method = 'SVD', param = list(k = 10))
rec_svd_400_10 <- as(predict(recmod_svd_400_10, test_400, n = n), 'list')




#svd 20

recmod_svd_400_20 <- Recommender(train_400, method = 'SVD', param = list(k = 20))
rec_svd_400_20 <- as(predict(recmod_svd_400_20, test_400, n = n), 'list')



# svd 30
recmod_svd_400_30 <- Recommender(train_400, method = 'SVD', param = list(k = 30))
rec_svd_400_30 <- as(predict(recmod_svd_400_30, test_400, n = n), 'list')


# svd 40
recmod_svd_400_40 <- Recommender(train_400, method = 'SVD', param = list(k = 40))
rec_svd_400_40 <- as(predict(recmod_svd_400_40, test_400, n = n), 'list')


# svd 50
recmod_svd_400_50 <- Recommender(train_400, method = 'SVD', param = list(k = 50))
rec_svd_400_50 <- as(predict(recmod_svd_400_50, test_400, n = n), 'list')
```


```{r}


svd10reclist <- unlist(names(recmod_ibcf_400) %>% map( ~(sum(
  rec_ibcf_400[[.x]] %in% rec_svd_400_10[[.x]]))/ 15 * 100))            


svd20reclist <- unlist(names(recmod_ibcf_400) %>% map( ~(sum(
  rec_ibcf_400[[.x]] %in%  rec_svd_400_20[[.x]]))/ 15 * 100)) 

svd30reclist <- unlist(names(recmod_ibcf_400) %>% map( ~(sum(
  rec_ibcf_400[[.x]] %in%  rec_svd_400_30[[.x]]))/ 15 * 100))

svd40reclist <- unlist(names(recmod_ibcf_400) %>% map( ~(sum(
  rec_ibcf_400[[.x]] %in%  rec_svd_400_40[[.x]]))/ 15 * 100))

svd50reclist <- unlist(names(recmod_ibcf_400) %>% map( ~(sum(
  rec_ibcf_400[[.x]] %in%  rec_svd_400_50[[.x]]))/ 15 * 100))

# dataframes
df_svd_400_10 <- as.data.frame(svd10reclist)
df_svd_400_20 <- as.data.frame(svd10reclist)
df_svd_400_30 <- as.data.frame(svd10reclist)
df_svd_400_40 <- as.data.frame(svd10reclist)
df_svd_400_50 <- as.data.frame(svd10reclist)
```

```{r}
#better version of above
# Funktion für die Berechnung der Überschneidung
calculate_overlap <- function(rec_ibcf, rec_svd, n) {
  names(rec_ibcf) %>% map(~ sum(rec_ibcf[[.x]] %in% rec_svd[[.x]]) / n * 100)
}

# Berechnung der Überschneidung für verschiedene SVD-Konfigurationen
svd10reclist <- calculate_overlap(rec_ibcf_400, rec_svd_400_10, 15)
svd20reclist <- calculate_overlap(rec_ibcf_400, rec_svd_400_20, 15)
svd30reclist <- calculate_overlap(rec_ibcf_400, rec_svd_400_30, 15)
svd40reclist <- calculate_overlap(rec_ibcf_400, rec_svd_400_40, 15)
svd50reclist <- calculate_overlap(rec_ibcf_400, rec_svd_400_50, 15)

# Erstellung von DataFrames
df_svd_400_10 <- as.data.frame(svd10reclist)
df_svd_400_20 <- as.data.frame(svd20reclist)
df_svd_400_30 <- as.data.frame(svd30reclist)
df_svd_400_40 <- as.data.frame(svd40reclist)
df_svd_400_50 <- as.data.frame(svd50reclist)

```


```{r}
#einschub, sollte so funktionieren

# Create a function to calculate overlap
calculate_overlap <- function(rec_ibcf, rec_svd, n, model_name) {
  data.frame(
    val = names(rec_ibcf) %>% 
      map_dbl(~ sum(rec_ibcf[[.x]] %in% rec_svd[[.x]]) / n * 100),
    model = model_name
  )
}

# Calculate overlap for different SVD configurations
df_svd_400_10 <- calculate_overlap(rec_ibcf_400, rec_svd_400_10, 15, 'SVD 10')
df_svd_400_20 <- calculate_overlap(rec_ibcf_400, rec_svd_400_20, 15, 'SVD 20')
df_svd_400_30 <- calculate_overlap(rec_ibcf_400, rec_svd_400_30, 15, 'SVD 30')
df_svd_400_40 <- calculate_overlap(rec_ibcf_400, rec_svd_400_40, 15, 'SVD 40')
df_svd_400_50 <- calculate_overlap(rec_ibcf_400, rec_svd_400_50, 15, 'SVD 50')

# Bind the data frames together
different_SVD <- bind_rows(
  df_svd_400_10, df_svd_400_20, df_svd_400_30,
  df_svd_400_40, df_svd_400_50
)
```

Wir können an unserer Tabelle sehen, das bei der Intersektion sich zwischen den SVD Modellen sich nicht wirklich etwas verändert.
```{r}
different_SVD%>% group_by(model)%>%summarise(mean(val))
```

Nun plotten wir das ganze noch, um es visuell darzustellen.
Es sieht bei allen ziemlich ähnlich aus. Es gibt fast keine Unterschiede.
```{r}
ggplot() + geom_histogram(data = different_SVD, aes(val, fill = model), binwidth = 1) +
  facet_wrap(.~model) +
  labs(x = 'Intersections in %',
       y = '#Users',
       title = 'Intersections of IBCF and various SVD')
```

