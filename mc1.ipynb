{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# install.packages(\"float\")\n",
    "# install.packages(\"RcppProgress\")\n",
    "# install.packages(\"arules\")\n",
    "# install.packages(\"registry\")\n",
    "# install.packages(\"irlba\")\n",
    "# install.packages(\"recosystem\")\n",
    "# install.packages(\"matrixStats\")\n",
    "# install.packages(\"tidyverse\")\n",
    "# install.packages(\"recommenderlab\")\n",
    "# install.packages(\"gridExtra\")\n",
    "# install.packages(\"testthat\")\n",
    "# install.packages(\"viridis\")\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "library(tidyverse)\n",
    "library(recommenderlab)\n",
    "library(gridExtra)\n",
    "data(MovieLense)\n",
    "library(testthat)\n",
    "library(viridis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "methods(class = class(MovieLense))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "df <- as(MovieLense, \"data.frame\")\n",
    "dfMeta <- as(MovieLenseMeta, \"data.frame\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First Insights\n",
    "We see that the dataframe contains 99'392 ratings with 943 users. The mininum rating is 1 and the maximum rating is 5, furthermore the average of all ratings is 3.53."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "tail(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "summary(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "## count the number of ratings per user\n",
    "user_ratings <- table(df$user)\n",
    "test_that(\"if its the sum of user ratings\", {\n",
    "    expect_equal(as.vector(user_ratings)[1], sum(df$user == 1))\n",
    "    expect_equal(as.vector(user_ratings)[2], sum(df$user == 10))\n",
    "})\n",
    "\n",
    "# count the number of unique users\n",
    "num_users <- length(unique(df$user))\n",
    "\n",
    "# count the number of movies\n",
    "num_movies <- length(unique(df$item))\n",
    "\n",
    "# total number of possible ratings\n",
    "totalRatings <- num_users * num_movies\n",
    "\n",
    "# count the number of missing ratings\n",
    "num_missing_ratings <- totalRatings - length(df$rating)\n",
    "\n",
    "# count the number of users who have not rated at least one movie\n",
    "num_users_missing_rating <- sum(user_ratings == 0)\n",
    "\n",
    "cat(\"Number of unique users:\", num_users, \"\\n\")\n",
    "cat(\"Number of unique movies:\", num_movies, \"\\n\")\n",
    "cat(\"Total number of possible ratings:\", totalRatings, \"\\n\")\n",
    "cat(\"Number of given ratings:\", nrow(df), \"\\n\")\n",
    "cat(\"Number of missing ratings:\", num_missing_ratings, \"\\n\")\n",
    "cat(\"Number of users who have not rated at least one movie:\", num_users_missing_rating, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1 Explorative Datenanalyse\n",
    "### 1. Welches sind die am häufigsten geschauten Genres/Filme?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# load necessary libraries\n",
    "library(dplyr)\n",
    "library(ggplot2)\n",
    "# Count the frequency of each movie and create  a new data frame\n",
    "movieCount <- df %>%\n",
    "    group_by(item) %>%\n",
    "    summarize(freq = n()) %>%\n",
    "    arrange(desc(freq))\n",
    "\n",
    "test_that(\"movieCount has the right frequency\", {\n",
    "    result <- sum(movieCount$freq)\n",
    "    expect_equal(result, nrow(df))\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plot the top 10 most frequent movies\n",
    "ggplot(\n",
    "    head(movieCount, 10),\n",
    "    aes(x = reorder(item, -freq), y = freq)) +\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Movie Titles\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Top 10 Most Frequent Movies\") +\n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the top 10 most frequent watched movies, further below we investigate which genres are the most frequent watched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# TODO create repo and invite tobias.lauber1\n",
    "# TODO comment all plots\n",
    "\n",
    "# Count the frequency of each genre and create a new data frame\n",
    "merged <- left_join(df, dfMeta, by = c(\"item\" = \"title\"))\n",
    "# Summarize by Genre\n",
    "dfMetaGenres <- select(dfMeta, -(1:3))\n",
    "# sum all genre columns\n",
    "genreCount <- colSums(dfMetaGenres, na.rm = TRUE)\n",
    "# create df\n",
    "genreCountDf <- data.frame(genre = names(genreCount), freq = genreCount)\n",
    "\n",
    "# Test stuff\n",
    "test_that(\"genreCountDf has the right frequency\", {\n",
    "    result <- sum(genreCountDf$freq)\n",
    "    expect_equal(result, sum(genreCount))\n",
    "    }\n",
    ")\n",
    "\n",
    "# Plot the top most frequent genres in descending order\n",
    "ggplot(\n",
    "  genreCountDf,\n",
    "  aes(x = reorder(genre, -freq), y = freq)) +\n",
    "  geom_bar(stat = \"identity\") +\n",
    "  xlab(\"Genres\") +\n",
    "  ylab(\"Total Frequency\") +\n",
    "  ggtitle(\"Most Frequently Watched Genres\") +\n",
    "  theme(axis.text.x = element_text(angle = 90, hjust = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the most frequently watches genres in descending order.  \n",
    "There is a clear imbalance in the genres, which can lead to a popularity bias, say the tendency to recommend popular items.  \n",
    "Which in turn can lead to even more people watching dramas and reinforce the bias.  \n",
    "An additional problem is that the same movie can be categorized in multiple genres, which can be misleading for the interpretation of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Wie verteilen sich die Nutzerratings der Filme gesamthaft bzw. nach Genres?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Distribution of Overall Ratings\n",
    "ggplot(\n",
    "  df,\n",
    "  aes(x = rating)) +\n",
    "  geom_histogram(binwidth = 0.5, fill = \"grey\", alpha = 0.7) +\n",
    "  xlab(\"Rating\") +\n",
    "  ylab(\"Frequency\") +\n",
    "  ggtitle(\"Distribution of User Ratings Overall\") +\n",
    "  theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of user ratings is overall positive, with the majority of users rating 3 or higher.  \n",
    "3, 4 and 5 dominate the ratings, but the problem with 3 is that there are users for whom a 3-star rating is a bad rating and for others it is a good rating.  \n",
    "We will see how to deal with this problem later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "genreRatings <- data.frame()\n",
    "mergedRatingsGenre <- left_join(df, dfMeta, by = c(\"item\" = \"title\"))\n",
    "genreCols <- names(dfMetaGenres)\n",
    "\n",
    "for(genre in genreCols) {\n",
    "    # Filter the data to only include ratings for movies that belong to the current genre\n",
    "    filteredData <- mergedRatingsGenre[mergedRatingsGenre[genre] == 1, ]\n",
    "    # Add ratings to a new data frame tagged by genre\n",
    "    rows <- data.frame(rating = filteredData$rating, genre = genre)\n",
    "    # Add new rows to result data frame\n",
    "    genreRatings <- rbind(genreRatings, rows)\n",
    "}\n",
    "ggplot(\n",
    "    genreRatings,\n",
    "    aes(x = rating)) +\n",
    "    geom_histogram(binwidth = 0.5, fill = \"grey\", alpha = 0.7) +\n",
    "    facet_wrap(~genre, scales = \"free_y\") +\n",
    "    xlab(\"Rating\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Distribution of User Ratings by Genre\") +\n",
    "    theme_minimal()\n",
    "\n",
    "# test stuff\n",
    "test_that(\"There are more genreRatings because one movie can be specified as multiple genres\", {\n",
    "  expect_false(identical(nrow(genreRatings), nrow(df)))\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Wie verteilen sich die mittleren Ratings pro Film bzw. pro Nutzer*in?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Average Rating per Movie\n",
    "avgRatingMovie <- df %>%\n",
    "    group_by(item) %>%\n",
    "    summarize(avgRating = mean(rating)) %>%\n",
    "    arrange(desc(avgRating))\n",
    "head(avgRatingMovie)\n",
    "# Distribution of average ratings per movie\n",
    "ggplot(avgRatingMovie, aes(x = avgRating)) + \n",
    "    geom_histogram(binwidth = 0.1, fill = \"grey\", alpha = 0.7) +\n",
    "    xlab(\"Average Rating per Movie\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Distribution of Average Ratings per Movie\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the highest frequency of the average ratings per movie is between 2.5 and 4.  \n",
    "Therefore most people rated movies between 3 and 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Average Ratings per User\n",
    "avgRatingUser <- df %>%\n",
    "    group_by(user) %>%\n",
    "    summarize(avgRating = mean(rating)) %>%\n",
    "    arrange(desc(avgRating))\n",
    "head(avgRatingUser)\n",
    "# Distribution of average ratings per user\n",
    "ggplot(avgRatingUser, aes(x = avgRating)) + \n",
    "    geom_histogram(binwidth = 0.1, fill = \"grey\", alpha = 0.7) +\n",
    "    xlab(\"Average Rating per User\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Distribution of Average Ratings per User\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest frequency for individual users is between 3.5 and 4.  \n",
    "That means the average user tends to rate movies generally positive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Welchen Einfluss hat die Normierung der Ratings pro Nutzer*in auf die Verteilung der mittleren Nutzer-ratings?\n",
    "Normalization eliminates user bias in collaborative filtering. Different users may have different rating standards, some may be more generous than others. Normalization centers each users rating around zero, making comparisons between users more meaningful, e.g. a normalized rating of zero would mean that the user finds the object average by their own standards. Before normalization, we do not see a clear difference between users rating preferences, while after normalization we see the similarities between users and their rating preferences, whether negative or positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Normalize the MovieLense data\n",
    "Norm <- normalize(MovieLense)\n",
    "dfNorm <- as(Norm, \"data.frame\")\n",
    "head(dfNorm)\n",
    "\n",
    "# Calculate average ratings per user\n",
    "avgNormRatingUser <- dfNorm %>%\n",
    "    group_by(user) %>%\n",
    "    summarize(avgRating = mean(rating)) %>%\n",
    "    arrange(desc(avgRating))\n",
    "\n",
    "# test that the mean is around zero\n",
    "test_that(\"The mean is around zero\", {\n",
    "    expect_true(all.equal(mean(avgNormRatingUser$avgRating), 0, tolerance = 0.01))\n",
    "})\n",
    "\n",
    "# Visualize for a subset of users for non normalized data\n",
    "df %>% filter(user %in% 1:12) %>%\n",
    "    ggplot(aes(x = user, y = rating)) +\n",
    "    geom_violin(color = \"grey\", fill = \"grey\", alpha = 0.5) +\n",
    "    labs(x = \"User\",\n",
    "         y = \"Ratings\",\n",
    "         title = \"Distribution of Ratings from Individual Users\",\n",
    "         subtitle = \"Subset of Users 1-12\")\n",
    "\n",
    "# Visualize for a subset of users for normalized data\n",
    "dfNorm %>% filter(user %in% 1:12) %>%\n",
    "    ggplot(aes(x = user, y = rating)) +\n",
    "    geom_violin(color = \"grey\", fill = \"grey\", alpha = 0.5) +\n",
    "    labs(x = \"User\",\n",
    "         y = \"Normalized Ratings\",\n",
    "         title = \"Normalized Distribution of Ratings from Individual Users\",\n",
    "         subtitle = \"Subset of Users 1-12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Welche strukturellen Charakteristika und Auffälligkeiten zeigt die User-Item Matrix?\n",
    "The user item matrix represents the interactions or ratings between users and items. \n",
    "In the image below the colored dots represent interactions or in our case ratings. \n",
    "The large number of empty space indicates that users have not interacted with any item.  \n",
    "This is a common problem in real world user-item matrices, as not every user interacts with every item.  \n",
    "The sparsity level of the item-user-matrix for the movielens dataset is ca. 93.7%.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "MovieLense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(viridis)\n",
    "# Set a random seed for reproducibility\n",
    "set.seed(42)\n",
    "\n",
    "smallM <- MovieLense[\n",
    "    sample(nrow(MovieLense), 50),sample(ncol(MovieLense), 50)\n",
    "]\n",
    "# Visualize the sparsity pattern of the smallMovieLense matrix\n",
    "library(Matrix)\n",
    "image(as(smallM, \"matrix\"), main = \"Sparsity Pattern of User-Item Matrix\", xlab = \"Items\", ylab = \"Users\", col = viridis(5))\n",
    "legend(\"topright\", legend = c(\"1\", \"2\", \"3\", \"4\", \"5\"), fill = viridis(5), title = \"Rating\")\n",
    "\n",
    "# Calculate sparsity level\n",
    "movieMatrix <- as(MovieLense, \"matrix\")\n",
    "totalN <- length(movieMatrix)\n",
    "filledN <- sum(\n",
    "    !is.na(movieMatrix) & movieMatrix > 0,\n",
    "    na.rm = TRUE\n",
    ")\n",
    "sparsityLevel <- (totalN - filledN) / totalN\n",
    "print(paste(\"Sparsity Level: \", round(sparsityLevel * 100, 2), \"%\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2 Datenreduktion\n",
    "### Aufgabe 2: Reduziere den MovieLens Datensatz auf rund 400 Nutzerinnen und 700 Filme, indem du Filme und Nutzerinnen mit sehr wenigen Ratings entfernst.\n",
    "#### 1. Anzahl Filme und Nutzer*innen sowie Sparsity vor und nach Datenreduktion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Set a random seed for reproducibility\n",
    "set.seed(42)\n",
    "\n",
    "# Filter out users and movies with fewer ratings\n",
    "# Adjust fUser and fMovie as per your requirement\n",
    "fUser <- 80\n",
    "fMovie <- 40\n",
    "\n",
    "filteredUsers <- df %>%\n",
    "    group_by(user) %>%\n",
    "    filter(n() >= fUser) %>%\n",
    "    ungroup()\n",
    "\n",
    "filteredMovies <- df %>%\n",
    "    group_by(item) %>%\n",
    "    filter(n() >= fMovie) %>%\n",
    "    ungroup()\n",
    "\n",
    "dfReduced <- df %>%\n",
    "    filter(user %in% filteredUsers$user, item %in% filteredMovies$item)\n",
    "\n",
    "uniqueUsers <- unique(dfReduced$user)\n",
    "\n",
    "# create dfreduced1 with first 300 users\n",
    "usersReduced1 <- uniqueUsers[1:300]\n",
    "dfReduced1 <- dfReduced %>%\n",
    "    filter(user %in% usersReduced1)\n",
    "\n",
    "# create dfreduced2 with users 101-400\n",
    "usersReduced2 <- uniqueUsers[101:400]\n",
    "dfReduced2 <- dfReduced %>%\n",
    "    filter(user %in% usersReduced2)\n",
    "\n",
    "## Calculate sparsity level\n",
    "calculateSparsity <- function(df) {\n",
    "    nUsers <- n_distinct(df$user)\n",
    "    nMovies <- n_distinct(df$item)\n",
    "    totalInteractions <- nUsers * nMovies\n",
    "    actualInteractions <- nrow(df)\n",
    "    sparsity <- 1 - (actualInteractions / totalInteractions)\n",
    "    return(sparsity)\n",
    "}\n",
    "\n",
    "# Investigate\n",
    "## Number of movies, users, sparsity level before and after\n",
    "nUsersBefore <- n_distinct(df$user)\n",
    "nMoviesBefore <- n_distinct(df$item)\n",
    "sparsityBefore <- calculateSparsity(df)\n",
    "sparsityAfter1 <- calculateSparsity(dfReduced1)\n",
    "sparsityAfter2 <- calculateSparsity(dfReduced2)\n",
    "cat(\"Treshold x for user ratings:\", fUser, \"\\n\")\n",
    "cat(\"Treshold y for movie ratings:\", fMovie, \"\\n\")\n",
    "cat(\"Number of movies dfReduced:\", n_distinct(dfReduced$item), \"\\n\")\n",
    "cat(\"Number of users dfReduced1:\", n_distinct(dfReduced1$user), \"\\n\")\n",
    "cat(\"Number of users dfReduced2:\", n_distinct(dfReduced2$user), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering out users with ratings less or equal than 80 gives us ca. 400 users and filtering out movies with ratings less or equal than 80 gives us ca. 700 movies.  \n",
    "The relative reduction for both are now round about 55%.  \n",
    "The sparsity level of the item-user-matrix for the reduced dataset is ca. 75%.  \n",
    "That means we reduced the dataset by 55% but only reduced the sparsity by 20%.  \n",
    "Dividing the reduced dataset further into two datasets where the first one has the 300 users with the most ratings and the second one has the users from 100 up to 400.  \n",
    "The sparsity level of the item-user-matrix for the first dataset is ca. 37% and for the second dataset ca. 60%.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Mittlere Nutzerratings pro Film vor und nach Datenreduktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "avgRatingMovieBefore <- df %>%\n",
    "    group_by(item) %>%\n",
    "    summarize(avgRating = mean(rating)) %>%\n",
    "    arrange(desc(avgRating))\n",
    "\n",
    "avgRatingMovieAfter1 <- dfReduced1 %>%\n",
    "    group_by(item) %>%\n",
    "    summarize(avgRating = mean(rating)) %>%\n",
    "    arrange(desc(avgRating))\n",
    "\n",
    "avgRatingMovieAfter2 <- dfReduced2 %>%\n",
    "    group_by(item) %>%\n",
    "    summarize(avgRating = mean(rating)) %>%\n",
    "    arrange(desc(avgRating))\n",
    "\n",
    "\n",
    "ggplot(avgRatingMovieBefore, aes(x = avgRating)) + \n",
    "    geom_histogram(binwidth = 0.1, fill = \"grey\", alpha = 0.7) +\n",
    "    xlab(\"Average Rating per Movie\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Distribution of Average Ratings per Movie before Data Reduction\") +\n",
    "    theme_minimal()\n",
    "ggplot(avgRatingMovieAfter1, aes(x = avgRating)) +\n",
    "    geom_histogram(binwidth = 0.5, fill = \"grey\", alpha = 0.7) +\n",
    "    xlab(\"Average Rating per Movie\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Distribution of Average Ratings per Movie after Data Reduction for Dataset 1\") +\n",
    "    theme_minimal()\n",
    "ggplot(avgRatingMovieAfter2, aes(x = avgRating)) +\n",
    "    geom_histogram(binwidth = 0.5, fill = \"grey\", alpha = 0.7) +\n",
    "    xlab(\"Average Rating per Movie\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Distribution of Average Ratings per Movie after Data Reduction for Dataset 2\") +\n",
    "    theme_minimal()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the further reduction of the dataset into two datasets, we see less frequency between the ratings.  \n",
    "Therefore the binwidth has to be adjusted.  \n",
    "Both datasets have some similarities in the distribution although the first ones ratings are on average higher,  \n",
    "whereas the second ones ratings are on average lower.  \n",
    "The users with the most ratings tend to rate higher than the users with less ratings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Zusatz für Gruppen: Quantifiziere die “Intersection over Union” aller reduzierten Datensätze paarweise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate Intersection over Union\n",
    "userIntersect <- intersect(dfReduced1$user, dfReduced2$user)\n",
    "userUnion <- union(dfReduced1$user, dfReduced2$user)\n",
    "userIoU <- length(userIntersect) / length(userUnion)\n",
    "cat(\"Intersection over Union for users:\", userIoU, \"\\n\")\n",
    "movieIntersect <- intersect(dfReduced1$item, dfReduced2$item)\n",
    "movieUnion <- union(dfReduced1$item, dfReduced2$item)\n",
    "movieIoU <- length(movieIntersect) / length(movieUnion)\n",
    "cat(\"Intersection over Union for movies:\", movieIoU, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The intersection over union is a measure of the overlap between two data sets.  \n",
    "For the user IoU, there is an overlap of about 67% between the first and second data sets.  \n",
    "For the movies IoU, the overlap between the first and second data sets is about 60%.  \n",
    "The overlap is quite reasonable and therefore the data sets are not too similar.  \n",
    "We could reduce the similarity by choosing other splitting techniques, e.g. instead of 400 users we could have 700,  \n",
    "and the indexing could range from 1 to 500 and from 201 to 700 and see how the IoU behaves."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.3 Analyse Ähnlichkeitsmatrix\n",
    "## Aufgabe 3: Erzeuge einen IBCF Recommender und analysiere die Ähnlichkeitsmatrix des trainierten Modelles für den reduzierten Datensatz.\n",
    "### 1. Zerlege den Datensatz in Trainings- und Testdaten im verhältnis 4:1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# convert from df to realRatingMatrix\n",
    "matrixReduced1 <- as(dfReduced1, \"realRatingMatrix\")\n",
    "\n",
    "evalScheme <- evaluationScheme(\n",
    "    matrixReduced1,\n",
    "    method = \"split\",\n",
    "    train = 0.8,\n",
    "    given = 5,\n",
    "    goodRating = 4\n",
    ")\n",
    "evalScheme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Trainiere ein IBCF Modell mit 30 Nachbarn und Cosine Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Get the training set from the evaluationScheme object\n",
    "trainData <- getData(evalScheme, \"train\")\n",
    "testData <- getData(evalScheme, \"known\")\n",
    "\n",
    "# Train the IBCF model\n",
    "trainedModel <- Recommender(\n",
    "    trainData, method = \"IBCF\", param = list(k = 30, method = \"Cosine\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Bestimme die Filme, die am häufigsten in der Cosine-Ähnlichkeitsmatrix auftauchen und analyisiere Vorkommen und Ratings im reduzierten Datensatz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Access the trained models list\n",
    "modelList <- getModel(trainedModel)\n",
    "\n",
    "# Extract the similiraty matrix\n",
    "simMatrix <- modelList$sim\n",
    "\n",
    "# Find the top 10 most similar movies\n",
    "top10 <- apply(simMatrix, 1, function(x)\n",
    "    order(x, decreasing = TRUE)[1:10]\n",
    ")\n",
    "\n",
    "# Unlist and tabulate to find most frequent\n",
    "mostFrequentMovies <- table(as.vector(top10))\n",
    "# Sort\n",
    "mostFrequentMovies <- sort(mostFrequentMovies, decreasing = TRUE)\n",
    "\n",
    "# process for ggplot2\n",
    "dfMostFrequentMovies <- as.data.frame(mostFrequentMovies)\n",
    "colnames(dfMostFrequentMovies) <- c(\"item\", \"freq\")\n",
    "\n",
    "# get the names for the movies for given ids in mostFreqentMovies\n",
    "dfMostFrequentMovies$MovieTitle <- dfMeta[as.numeric(names(mostFrequentMovies)), \"title\"]\n",
    "# Visualize\n",
    "ggplot(\n",
    "    head(dfMostFrequentMovies, 10),\n",
    "    aes(x = reorder(MovieTitle, -freq), y = freq)) +\n",
    "    geom_bar(stat = \"identity\") +\n",
    "    xlab(\"Movie Titles\") +\n",
    "    ylab(\"Frequency\") +\n",
    "    ggtitle(\"Top 10 Most Frequent Movies in Similarity Matrix\") +\n",
    "    theme(axis.text.x = element_text(angle = 90, hjust = 1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Wiederhole die Analyse, indem du bei der Datenpartitionierung die Anzahl nicht-maskierter Produkte der Test-User veränderst und kommentiere den Einfluss auf die Resultate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "trainSize <- length(dfReduced1$user) * 0.8\n",
    "testSize <- length(dfReduced1$user) * 0.2\n",
    "cat(\"Train size:\", trainSize, \"\\n\")\n",
    "cat(\"Test size:\", testSize, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Convert from df to realRatingMatrix\n",
    "matrixReduced1 <- as(dfReduced1, \"realRatingMatrix\")\n",
    "\n",
    "# Define the given values to iterate over\n",
    "given_values <- c(5, 10 , 20, 40)\n",
    "\n",
    "# Iterate over the different given values\n",
    "for (given in given_values) {\n",
    "    cat(\"Processing for given =\", given, \"\\n\")\n",
    "    \n",
    "    # Create evaluation scheme\n",
    "    evalScheme <- evaluationScheme(\n",
    "        matrixReduced1,\n",
    "        method = \"split\",\n",
    "        train = 0.8,\n",
    "        given = given,\n",
    "        goodRating = 4\n",
    "    )\n",
    "    \n",
    "    # Train the IBCF model\n",
    "    trained_model <- Recommender(\n",
    "        getData(evalScheme, \"train\"), \n",
    "        method = \"IBCF\", \n",
    "        param = list(k = 30, method = \"Cosine\")\n",
    "    )\n",
    "\n",
    "    # Extract the similarity matrix\n",
    "    simMatrix <- getModel(trained_model)$sim\n",
    "\n",
    "    # Find the top 10 most similar movies\n",
    "    top10 <- apply(simMatrix, 1, function(x)\n",
    "        order(x, decreasing = TRUE)[1:10]\n",
    "    )\n",
    "\n",
    "    # Unlist and tabulate to find most frequent\n",
    "    mostFrequentMovies <- table(as.vector(top10))\n",
    "    # Sort\n",
    "    mostFrequentMovies <- sort(mostFrequentMovies, decreasing = TRUE)\n",
    "\n",
    "    # Process for ggplot2\n",
    "    dfMostFrequentMovies <- as.data.frame(mostFrequentMovies)\n",
    "    colnames(dfMostFrequentMovies) <- c(\"item\", \"freq\")\n",
    "\n",
    "    # Get the names for the movies for given ids in mostFreqentMovies\n",
    "    dfMostFrequentMovies$MovieTitle <- dfMeta[as.numeric(names(mostFrequentMovies)), \"title\"]\n",
    "    \n",
    "    # Visualize\n",
    "    p <- ggplot(\n",
    "        head(dfMostFrequentMovies, 10),\n",
    "        aes(x = reorder(MovieTitle, -freq), y = freq)) +\n",
    "        geom_bar(stat = \"identity\") +\n",
    "        xlab(\"Movie Titles\") +\n",
    "        ylab(\"Frequency\") +\n",
    "        ggtitle(paste(\"Top 10 Most Frequent Movies in Similarity Matrix for given =\", given)) +\n",
    "        theme(axis.text.x = element_text(angle = 90, hjust = 1)\n",
    "    )\n",
    "    print(p)\n",
    "    # ggsave(paste(\"similarity_matrix_given_\", given, \".png\", sep=\"\"))\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The IBCF Recommender uses a test set $Y$ of user profiles that are not part of the training but of the predictions. Additionally, there is a set $Z$ of masked ratings to evaluate the prediction. For the masking process we use the parameter `Given-x` which randomly selects $x$ from all test users for the prediction, the rest is part of the evaluation. We see that for different given values the same result is not always obtained, e.g. the recommendation results for given = 20 differ from those of the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.4 Implementierung Ähnlichkeitsmatrix\n",
    "## Aufgabe 4 (DIY): Implementiere Funktionen zur Berechnung von Ähnlichkeitsmatrizen bei IBCF Recommenders für (a) Cosine Similarity mit ordinale Ratings und (b) Jaccard Similarity mit binären Ratings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Vergleiche die Resultate beider Funktionen hinsichtlich Übereinstimmung und Laufzeit mit dem Resultat der Funktion Recommender() und der eines anderen R-Paketes anhand 100 zufällig gewählter Filme.\n",
    "The custom function and the proxy calculation have similar runtimes. They are 4 times higher than the Recommender() function.  \n",
    "\n",
    "The MAE value between cosineSimMatrix and recCosineSimMatrix (0.30) indicates a greater degree of dissimilarity between these two matrices. This indicates that on average there are remarkable absolute differences between the two matrices.  \n",
    "\n",
    "On the other hand, the MAE value between cosineSimMatrix and cosineSimMatrixProxy (0.15) is lower, indicating a greater degree of similarity between these two matrices. This indicates that, on average, cosineSimMatrixProxy agrees better with those in cosineSimMatrix than with the recCosineSimMatrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(recommenderlab)\n",
    "\n",
    "if (!all(c(\"user\", \"item\", \"rating\") %in% colnames(dfReduced1))) {\n",
    "    stop(\"dfReduced1 does not contain the columns 'user', 'item', and 'rating'\")\n",
    "}\n",
    "\n",
    "calculateCosineSimilarity <- function(ratingMatrix) {\n",
    "    # Ensure matrix is in the correct format\n",
    "    if (!inherits(ratingMatrix, \"realRatingMatrix\")) {\n",
    "        stop(\"Input is not a realRatingMatrix\")\n",
    "    }\n",
    "    \n",
    "    # Access the data slot and transpose to work with items as rows\n",
    "    mat <- t(as(ratingMatrix@data, \"matrix\"))\n",
    "    \n",
    "    # Normalize each row (item) of the matrix\n",
    "    mat <- t(apply(mat, 1, function(row) {\n",
    "        norm <- sqrt(sum(row^2))\n",
    "        if(norm > 0) row / norm else row\n",
    "    }))\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    simMatrix <- mat %*% t(mat)\n",
    "    \n",
    "    return(simMatrix)\n",
    "}\n",
    "\n",
    "library(reshape2)\n",
    "\n",
    "# Ensuring dfReduced1 is a data frame with the required columns\n",
    "if (!all(c(\"user\", \"item\", \"rating\") %in% colnames(dfReduced1))) {\n",
    "    stop(\"dfReduced1 does not contain the columns 'user', 'item', and 'rating'\")\n",
    "}\n",
    "\n",
    "# Convert dfReduced1 into a wide format matrix\n",
    "wideMatrix <- acast(dfReduced1, user ~ item, value.var = \"rating\")\n",
    "\n",
    "# Create a realRatingMatrix from the wide format matrix\n",
    "realRatingMatrix1 <- as(wideMatrix, \"realRatingMatrix\")\n",
    "\n",
    "# Selecting 100 random movies\n",
    "set.seed(123)\n",
    "selected_movies <- sample(colnames(realRatingMatrix1), 100)\n",
    "\n",
    "# Reducing the matrix to only selected movies\n",
    "reducedMatrix1 <- realRatingMatrix1[, selected_movies]\n",
    "\n",
    "# Checking dimensions\n",
    "test_that(\"reducedMatrix1 has the right dimensions\", {\n",
    "    expect_equal(dim(reducedMatrix1), c(300, 100))\n",
    "})\n",
    "cat(\"Dimensions of reducedMatrix1:\", dim(reducedMatrix1), \"\\n\")\n",
    "\n",
    "# Compute Cosine Similarity Matrix using the custom function\n",
    "startTime <- Sys.time()\n",
    "cosineSimMatrix <- calculateCosineSimilarity(reducedMatrix1)\n",
    "endTime <- Sys.time()\n",
    "runtimeCustom <- endTime - startTime\n",
    "cat(\"Runtime for custom function:\", runtimeCustom, \"\\n\")\n",
    "test_that(\"cosineSimMatrix has the right dimensions\", {\n",
    "    expect_equal(dim(cosineSimMatrix), c(100, 100))\n",
    "})\n",
    "cat(\"Dimensions of cosineSimMatrix:\", dim(cosineSimMatrix), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(recommenderlab)\n",
    "\n",
    "# Use the Recommender() function with method IBCF and cosine similarity\n",
    "startTime <- Sys.time()\n",
    "ibcf_model <- Recommender(\n",
    "    data = reducedMatrix1,\n",
    "    method = \"IBCF\",\n",
    "    param = list(method = \"Cosine\", k = 30)\n",
    ")\n",
    "\n",
    "# Extract the similarity matrix from the model\n",
    "recCosineSimMatrix <- as.matrix(getModel(ibcf_model)$sim)\n",
    "endTime <- Sys.time()\n",
    "runtimeRec <- endTime - startTime\n",
    "cat(\"Runtime for Recommender():\", runtimeRec, \"\\n\")\n",
    "\n",
    "# Check the dimensions of the similarity matrix\n",
    "cat(\"Dimensions of recCosineSimMatrix:\", dim(recCosineSimMatrix), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "calculateCosineSimilarityProxy <- function(ratingMatrix) {\n",
    "    # Ensure matrix is in the correct format\n",
    "    if (!inherits(ratingMatrix, \"realRatingMatrix\")) {\n",
    "        stop(\"Input is not a realRatingMatrix\")\n",
    "    }\n",
    "    \n",
    "    # Convert the rating matrix to a matrix\n",
    "    mat <- as(ratingMatrix@data, \"matrix\")\n",
    "    \n",
    "    # Calculate Cosine Similarity for items (movies)\n",
    "    simMatrix <- proxy::simil(t(mat), method = \"cosine\")\n",
    "    \n",
    "    return(simMatrix)\n",
    "}\n",
    "\n",
    "# Calculate Cosine Similarity using the modified function\n",
    "startTime <- Sys.time()\n",
    "cosineSimMatrixProxy <- calculateCosineSimilarityProxy(reducedMatrix1)\n",
    "endTime <- Sys.time()\n",
    "runtimeProxy <- endTime - startTime\n",
    "cat(\"Runtime for calculateCosineSimilarityProxy:\", runtimeProxy, \"\\n\")\n",
    "cat(\"Dimensions of cosineSimMatrixProxy:\", dim(cosineSimMatrixProxy), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the Mean Absolute Error (MAE) between cosineSimMatrix and recCosineSimMatrix\n",
    "suppressWarnings({mae_rec <- mean(abs(cosineSimMatrix - recCosineSimMatrix), na.rm = TRUE)})\n",
    "\n",
    "# Calculate the Mean Absolute Error (MAE) between cosineSimMatrix and cosineSimMatrixProxy\n",
    "suppressWarnings({mae_proxy <- mean(abs(cosineSimMatrix - cosineSimMatrixProxy), na.rm = TRUE)})\n",
    "\n",
    "# Display the MAE values\n",
    "cat(\"Mean Absolute Error with recCosineSimMatrix:\", mae_rec, \"\\n\")\n",
    "cat(\"Mean Absolute Error with cosineSimMatrixProxy:\", mae_proxy, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "getJaccardSim <- function(ratingMatrix, nUser, nItem){\n",
    "  \n",
    "  slicedMatrixBin <- as(binarize(ratingMatrix[1:nUser, 1:nItem], minRating=4), \"matrix\")\n",
    "  \n",
    "  slicedMatrixBinT <- t(slicedMatrixBin)\n",
    "  \n",
    "  matrixCrossProd <- tcrossprod(slicedMatrixBinT)\n",
    "  \n",
    "  im <- which(matrixCrossProd > 0, arr.ind=TRUE)\n",
    "  b <- rowSums(slicedMatrixBinT)\n",
    "  aim <- matrixCrossProd[im]\n",
    "  \n",
    "  j = sparseMatrix(\n",
    "            i = im[,1],\n",
    "            j = im[,2],\n",
    "            x = aim / (b[im[,1]] + b[im[,2]] - aim),\n",
    "            dims = dim(matrixCrossProd)\n",
    "      )\n",
    "  \n",
    "  j <- data.matrix(j)\n",
    "  \n",
    "  j\n",
    "}\n",
    "\n",
    "jaccardSim <- getJaccardSim(matrixReduced1, 100, 100)\n",
    "jaccardSim[1:5, 1:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualisiere und vergleiche die Verteilung der Ähnlichkeiten von Cosine Similarity für ordinale Ratings und von Jaccard Similarity für binäre Ratings mittels den von dir implementierten Funktionen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "wideMatrix <- acast(dfReduced1, user ~ item, value.var = \"rating\")\n",
    "realRatingMatrix1 <- as(wideMatrix, \"realRatingMatrix\")\n",
    "set.seed(123)\n",
    "selected_movies <- sample(colnames(realRatingMatrix1), 100)\n",
    "reducedMatrix1 <- realRatingMatrix1[, selected_movies]\n",
    "cosineSimMatrix <- calculateCosineSimilarity(reducedMatrix1)\n",
    "\n",
    "jaccardSim <- getJaccardSim(matrixReduced1, 100, 100)\n",
    "\n",
    "rownames(cosineSimMatrix) <- NULL\n",
    "colnames(cosineSimMatrix) <- NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "convert_to_long <- function(matrix, name = \"matrix\") {\n",
    "    as.data.frame(as.table(as.matrix(matrix))) %>%\n",
    "        rename(Item1 = Var1, Item2 = Var2, Similarity = Freq) %>%\n",
    "        mutate(Matrix = name)\n",
    "}\n",
    "cosineLong <- convert_to_long(cosineSimMatrix, \"Custom Cosine\")\n",
    "jaccardLong <- convert_to_long(jaccardSim, \"Jaccard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "combinedData <- rbind(cosineLong, jaccardLong)\n",
    "combinedData[1:5, 1:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "ggplot(combinedData, aes(x = Item1, y = Item2, fill = Similarity)) + \n",
    "  geom_tile() + \n",
    "  facet_wrap(~Matrix, scales = \"free\") + \n",
    "  theme_minimal() + \n",
    "  labs(title = \"Comparison of Cosine and Jaccard Similarity Matrices\", x = \"Item\", y = \"Item\", fill = \"Similarity\") + \n",
    "  scale_fill_viridis_c(option = \"C\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.5 Produktabdeckung - Top-N Listen von IBCF und UBCF [12 Punkte]\n",
    "Aufgabe 5: Vergleiche und diskutiere Top-N Empfehlungen von IBCF und UBCF Modellen mit 30 Nachbarn\n",
    "und Cosine Similarity für den reduzierten Datensatz.\n",
    "### 1. Berechne die Top-15 Empfehlungen aller Testnutzer*innen via IBCF und UBCF,\n",
    "\n",
    "Hinweise:\n",
    "• Diese Aufgabe ist eine Fortsetzung von Aufgabe 3.\n",
    "• Die Analyse soll sinnvoll Visualisierungen und Tabellen verwenden und die Resultate diskutieren.\n",
    "• Die Aufgabe beleuchtet, wie Empfehlungen unterschiedlicher Modelle den Produktkatalog abdecken.\n",
    "Diskutiere in diesem Zusammenhang die pauschale Behauptung “Recommender Systeme machen\n",
    "für alle Nutzer*innen die gleichen Empfehlungen”."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(recommenderlab)\n",
    "\n",
    "# Assuming 'reducedMatrix1' is your reduced realRatingMatrix data set\n",
    "# Split data into training and test sets\n",
    "evaluationScheme <- evaluationScheme(reducedMatrix1, method = \"split\", train = 0.8, given = -1, goodRating = 4)\n",
    "trainSet <- getData(evaluationScheme, \"train\")\n",
    "testSet <- getData(evaluationScheme, \"known\")\n",
    "\n",
    "# Assuming `reducedMatrix` is your reduced data set\n",
    "# and `testSet` is the portion of your data used for testing\n",
    "\n",
    "# Create IBCF model\n",
    "ibcfModel <- Recommender(trainSet, method = \"IBCF\", param = list(k = 30, method = \"Cosine\"))\n",
    "ibcf_model\n",
    "ubcfModel <- Recommender(trainSet, method = \"UBCF\", param = list(method = \"Cosine\"))\n",
    "ubcfModel\n",
    "\n",
    "# Function to get top N recommendations\n",
    "getTopN <- function(model, data, n = 15) {\n",
    "    sapply(seq(nrow(data)), function(i) {\n",
    "        recs <- predict(model, newdata = data[i, ], n = n)\n",
    "        as(recs, \"list\")[[1]]\n",
    "    })\n",
    "}\n",
    "\n",
    "# Get top 15 recommendations for all users\n",
    "top15_ibcf <- getTopN(ibcfModel, testSet)\n",
    "top15_ubcf <- getTopN(ubcfModel, testSet)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Vergleiche die Top-15 Empfehlungen von IBCF vs UBCF für drei Testnutzer*innen mittels Tabelle,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Function to get top N recommendations and return as a list\n",
    "getTopN <- function(model, data, n = 15) {\n",
    "  rec_list <- list()\n",
    "  for (i in 1:nrow(data)) {\n",
    "    recs <- predict(model, newdata = data[i, ], n = n)\n",
    "    rec_list[[rownames(data)[i]]] <- as(recs, \"list\")[[1]]\n",
    "  }\n",
    "  return(rec_list)\n",
    "}\n",
    "\n",
    "# Get top 15 recommendations for all users\n",
    "top15_ibcf <- getTopN(ibcfModel, testSet)\n",
    "top15_ubcf <- getTopN(ubcfModel, testSet)\n",
    "\n",
    "# Randomly select three test users\n",
    "sample_users <- sample(rownames(testSet), 3)\n",
    "\n",
    "# Extract recommendations for these users and create a data frame for comparison\n",
    "comparison <- lapply(sample_users, function(u) {\n",
    "  ibcf_rec <- top15_ibcf[[u]]\n",
    "  ubcf_rec <- top15_ubcf[[u]]\n",
    "  data.frame(User = u, IBCF = ibcf_rec, UBCF = ubcf_rec)\n",
    "})\n",
    "\n",
    "# View comparison\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Visualisiere und diskutiere für alle Testnutzer*innen summarisch die Verteilung der Top-15 Empfehlungen von IBCF und UBCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "library(recommenderlab)\n",
    "library(ggplot2)\n",
    "library(dplyr)\n",
    "\n",
    "# [Previous code steps to create the models and get top-N recommendations]\n",
    "\n",
    "# Function to create a data frame for plotting\n",
    "prepareForPlot <- function(recList, model) {\n",
    "  recData <- do.call(rbind, lapply(recList, function(recs, user) {\n",
    "    data.frame(User = user, Item = recs, Model = model)\n",
    "  }, user = names(recList)))\n",
    "  return(recData)\n",
    "}\n",
    "\n",
    "# Prepare data for plotting\n",
    "plotDataIBCF <- prepareForPlot(top15_ibcf, \"IBCF\")\n",
    "plotDataUBCF <- prepareForPlot(top15_ubcf, \"UBCF\")\n",
    "\n",
    "# Combine data from both models\n",
    "combinedPlotData <- rbind(plotDataIBCF, plotDataUBCF)\n",
    "\n",
    "# Plotting the distribution of recommendations\n",
    "ggplot(combinedPlotData, aes(x = Item, fill = Model)) +\n",
    "  geom_histogram(stat = \"count\", position = \"dodge\") +\n",
    "  theme_minimal() +\n",
    "  labs(title = \"Distribution of Top-15 Recommendations\",\n",
    "       x = \"Item\", y = \"Count\",\n",
    "       fill = \"Model\") +\n",
    "  theme(axis.text.x = element_text(angle = 45, hjust = 1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.6 Personalisierte Empfehlungen - Top-N Listen von IBCF und UBCF [16 Punkte]\n",
    "Aufgabe 6: Untersuche den Einfluss von Ratings und Modelltyp auf Top-N Empfehlungen für den re-\n",
    "duzierten Datensatz und vergleiche die Empfehlungen über alle Testnutzer*innen in den Top-15 Listen,\n",
    "wenn Modelltyp und Rating verändert werden.\n",
    "Vergleiche die Verteilung übereinstimmender Empfehlungen aller Testnutzer*innen in den Top-15 Listen für\n",
    "### 1. IBCF vs UBCF, beide mit ordinalen Ratings und Cosine Similarity,\n",
    "Hinweise:\n",
    "• Diese Aufgabe ist eine Fortsetzung von Aufgabe 5.\n",
    "• Gefordert ist eine vergleichende, statistische Analyse inklusive Visualisierung. Der erste Schritt dabei\n",
    "ist die Übereinstimmung der Empfehlungen pro Nutzer*in zu untersuchen.\n",
    "• Implementiere eine Funktion für die Überprüfung der Übereinstimmung von Empfehlungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "evaluationScheme <- evaluationScheme(reducedMatrix1, method = \"split\", train = 0.8, given = -1, goodRating = 4)\n",
    "trainSet <- getData(evaluationScheme, \"train\")\n",
    "testSet <- getData(evaluationScheme, \"known\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommender of type ‘IBCF’ for ‘realRatingMatrix’ \n",
       "learned using 240 users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Recommender of type ‘UBCF’ for ‘realRatingMatrix’ \n",
       "learned using 60 users."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ibcf <- Recommender(trainSet, \"IBCF\", param=list(k= 30, method = \"cosine\"))\n",
    "ibcf\n",
    "\n",
    "ubcf <- Recommender(testSet, \"UBCF\", param=list(nn= 30, method = \"cosine\"))\n",
    "ubcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Recommendations as ‘topNList’ with n = 15 for 60 users. "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rubcftopNList_1 <- predict(ibcf, testSet, n=15)\n",
    "rubcftopNList_1\n",
    "\n",
    "ubcftopNList <- predict(ubcf, test_2, n=15)\n",
    "rubcftopNList_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in h(simpleError(msg, call)): Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl für Funktion 'as.array': Objekt 'ribcftopNList_1' nicht gefunden\n",
     "output_type": "error",
     "traceback": [
      "Error in h(simpleError(msg, call)): Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl für Funktion 'as.array': Objekt 'ribcftopNList_1' nicht gefunden\nTraceback:\n",
      "1. topN_df(ribcftopNList_1)",
      "2. table(unlist(as.array(as(topNList, \"list\"))))   # at line 2 of file <text>",
      "3. unlist(as.array(as(topNList, \"list\")))",
      "4. as.array(as(topNList, \"list\"))",
      "5. as(topNList, \"list\")",
      "6. .class1(object)",
      "7. .handleSimpleError(function (cond) \n . .Internal(C_tryCatchHelper(addr, 1L, cond)), \"Objekt 'ribcftopNList_1' nicht gefunden\", \n .     base::quote(eval(expr, envir, enclos)))",
      "8. h(simpleError(msg, call))"
     ]
    }
   ],
   "source": [
    "topN_df <- function(topNList){\n",
    "  counts <- table(unlist(as.array(as(topNList, \"list\"))))\n",
    "  df <- data.frame(Movie = names(counts), Count = unname(counts)) %>%\n",
    "    select(\"Movie\", \"Count.Freq\") %>%\n",
    "    rename(\"Count\" = \"Count.Freq\") %>%\n",
    "    arrange(desc(Count))  \n",
    "  df\n",
    "}\n",
    "\n",
    "# alle dfs erstellen\n",
    "ribcftopN_df_1 <- topN_df(ribcftopNList_1)\n",
    "ribcftopN_df_1\n",
    "ribcftopN_df_2 <- topN_df(ribcftopNList_2)\n",
    "ribcftopN_df_2\n",
    "\n",
    "rubcftopN_df_1 <- topN_df(rubcftopNList_1)\n",
    "rubcftopN_df_1\n",
    "rubcftopN_df_2 <- topN_df(rubcftopNList_2)\n",
    "rubcftopN_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "ename": "ERROR",
     "evalue": "Error in h(simpleError(msg, call)): Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl für Funktion 'head': Objekt 'ribcftopN_df_1' nicht gefunden\n",
     "output_type": "error",
     "traceback": [
      "Error in h(simpleError(msg, call)): Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl für Funktion 'head': Objekt 'ribcftopN_df_1' nicht gefunden\nTraceback:\n",
      "1. grid.arrange(top15_df_visualize(ribcftopN_df_1, \"ribcf 1\"), top15_df_visualize(rubcftopN_df_1, \n .     \"rubcf 1\"), ncol = 2)",
      "2. arrangeGrob(...)",
      "3. top15_df_visualize(ribcftopN_df_1, \"ribcf 1\")",
      "4. topNList %>% head(15) %>% ggplot(aes(x = reorder(Movie, Count), \n .     y = Count))   # at line 2-9 of file <text>",
      "5. ggplot(., aes(x = reorder(Movie, Count), y = Count))",
      "6. head(., 15)",
      "7. .handleSimpleError(function (cond) \n . .Internal(C_tryCatchHelper(addr, 1L, cond)), \"Objekt 'ribcftopN_df_1' nicht gefunden\", \n .     base::quote(eval(expr, envir, enclos)))",
      "8. h(simpleError(msg, call))"
     ]
    }
   ],
   "source": [
    "top15_df_visualize <- function(topNList, subtitle){\n",
    "  topNList %>% head(15) %>% \n",
    "    ggplot(aes(x = reorder(Movie, Count), y = Count)) +\n",
    "    geom_bar(stat = \"identity\", fill = \"limegreen\", alpha = 0.5, color = \"black\") +\n",
    "    coord_flip() +\n",
    "    labs(x = \"Movie\", \n",
    "         y = \"Anzahl\", \n",
    "         title = \"Top-15 Empfehlungen\",\n",
    "         subtitle = subtitle)\n",
    "}\n",
    "\n",
    "grid.arrange(top15_df_visualize(ribcftopN_df_1, \"ribcf 1\"),\n",
    "             top15_df_visualize(rubcftopN_df_1, \"rubcf 1\"),\n",
    "             ncol = 2)\n",
    "\n",
    "\n",
    "grid.arrange(top15_df_visualize(ribcftopN_df_2, \"ribcf 2\"),\n",
    "             top15_df_visualize(rubcftopN_df_2, \"rubcf 2\"),\n",
    "             ncol = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Erste Datenreduktion\"\n"
     ]
    },
    {
     "ename": "ERROR",
     "evalue": "Error in h(simpleError(msg, call)): Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl für Funktion 'print': Objekt 'ribcftopN_df_1' nicht gefunden\n",
     "output_type": "error",
     "traceback": [
      "Error in h(simpleError(msg, call)): Fehler bei der Auswertung des Argumentes 'x' bei der Methodenauswahl für Funktion 'print': Objekt 'ribcftopN_df_1' nicht gefunden\nTraceback:\n",
      "1. compare_ibcf_ubcf(ribcftopN_df_1, rubcftopN_df_1)",
      "2. print(paste(\"Anzahl IBCF:\", nrow(ibcf)))   # at line 2 of file <text>",
      "3. paste(\"Anzahl IBCF:\", nrow(ibcf))",
      "4. nrow(ibcf)",
      "5. .handleSimpleError(function (cond) \n . .Internal(C_tryCatchHelper(addr, 1L, cond)), \"Objekt 'ribcftopN_df_1' nicht gefunden\", \n .     base::quote(eval(expr, envir, enclos)))",
      "6. h(simpleError(msg, call))"
     ]
    }
   ],
   "source": [
    "compare_ibcf_ubcf <- function(ibcf, ubcf) {\n",
    "  print(paste(\"Anzahl IBCF:\", nrow(ibcf)))\n",
    "  print(paste(\"Anzahl UBCF:\", nrow(ubcf)))\n",
    "\n",
    "  IntersectordRatCosine <- intersect(ibcf$Movie, ubcf$Movie)\n",
    "\n",
    "  print(paste(\"Anzahl gemeinsame Empfehlungen:\", length(IntersectordRatCosine)))\n",
    "  print(paste(\"Anteil IBCF:\", length(IntersectordRatCosine) / nrow(ibcf) * 100))\n",
    "  print(paste(\"Anteil UBCF:\", length(IntersectordRatCosine) / nrow(ubcf) * 100))\n",
    "}\n",
    "\n",
    "print(\"Erste Datenreduktion\")\n",
    "compare_ibcf_ubcf(ribcftopN_df_1, rubcftopN_df_1)\n",
    "print(\"Zweite Datenreduktion\")\n",
    "compare_ibcf_ubcf(ribcftopN_df_2, rubcftopN_df_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. IBCF vs UBCF, beide mit ordinalen, normalisierten Ratings und Cosine Similarity.\n",
    "Hinweise:\n",
    "• Diese Aufgabe ist eine Fortsetzung von Aufgabe 5.\n",
    "• Gefordert ist eine vergleichende, statistische Analyse inklusive Visualisierung. Der erste Schritt dabei\n",
    "ist die Übereinstimmung der Empfehlungen pro Nutzer*in zu untersuchen.\n",
    "• Implementiere eine Funktion für die Überprüfung der Übereinstimmung von Empfehlungen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
